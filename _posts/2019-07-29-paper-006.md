---
title: 【论文研读】 006 Neural Reading Comprehension and Beyond
date: 2019-07-29 13:13:00
---


https://stacks.stanford.edu/file/druid:gd576xb1833/thesis-augmented.pdf

作者：
[陈丹琦](https://www.cs.princeton.edu/~danqic/)


---

### 论文动机

为了处理这样一段文本，NLP社区花了几十年的时间来解决文本理解各个方面的不同任务，包括:
1. 词性标注（part-of-speech tagging）。这需要我们的机器理解文本中的单词词性。例如，第一句话中Alyssa got to the beach after a long trip。其中Alyssa是一个专有名词（proper noun），beach和trip是常见名词（common noun），got是动词的过去式（verb in its past tense），long是形容词（adjective），after是介词（preposition）。
2. 命名实体识别（named entity recognition）。我们的机器也应该明白，故事中是Alyssa、Ellen、Kristen人物的名字，而Charlotte、Atlanta和Miami是地点的名字。
3. 语法解析（syntactic parsing）。为了理解每个句子的意思，我们的机器还需要理解单词之间的关系，或者语法（grammatical）结构。还是用故事中的第一句话举例：Alyssa got to the beach after a long trip，，机器应该理解Alyssa是主语，beach是动词got的宾语，而after a long trip作为一个整体是一个介词短语，它描述了动词与时间的关系。
4. 指代消解。此外，我们的机器甚至需要理解句子之间的关系。例如，She ‘s now in Miami这句话中提到的She指的是第一句中提到的Alyssa，而提到的The girls指的是前面句子中提到的Alyssa、Ellen、Kristen和Rachel。



是否有一种综合评价可以检验所有这些方面，并探索更深层次的理解？
阅读理解的任务——在一篇文章中回答理解性问题——是一种恰当而重要的方法。就像我们使用阅读理解测试来衡量一个人对一段文字的理解程度一样，我们相信它也可以在评估计算机系统对人类语言的理解程度方面发挥同样的作用。

我们的计算机系统必须理解文本的各个方面来正确地回答这些问题。


由于问题可以被设计成问询我们关心的方面，所以阅读理解可能是评估语言理解最合适的任务（reading comprehension could be the most suitable task for evaluating language understanding）。

神经阅读理解（neural reading comprehension）已经被证明比非神经（网络）的、基于特征的模型更有效。


阅读理解这个领域有着悠久的历史——早在20世纪70年代，研究者就已经认识到它是测试计算机程序语言理解能力的重要方法（Lehnert， 1977）。
然而，这个领域已经被忽视了几十年。直到最近，它才得到了大量的关注，并取得了快速的进展（参见Figure 1.2作为一个例子），包括我们将在本文中详细介绍的我们付出的努力。
最近阅读理解的成功可以归因于两个原因：1）以（文章、问题、答案）三元组的形式的大规模监督数据集创建；2）神经阅读理解模型的建立。


如果我们能够构建出高性能的阅读理解系统，它们将成为问答和对话系统等应用的关键技术（they would be a crucial technology for applications such as question answering and dialogue systems）。


与传统的基于特征的分类器相比，神经模型更善于学习词汇匹配和释义，而现有系统的推理能力仍然相当有限。


### 阅读理解的发展

建立自动阅读理解系统的历史可以追溯到四十多年前。在20世纪70年代，研究人员已经认识到把阅读理解作为一种方法来测试计算机程序对语言的理解能力的重要性。

最著名的早期作品之一是Lehnert（1977）中详细描述的QUALM。基于脚本和计划框架，Lehnert（1977）设计了一个问答的理论，并且专注于语用问题和故事上下文在问答中的重要性，来作为对人类阅读理解的建模（Schank and Abelson， 1977）。这个早期工作为语言理解设置了一个强大的愿景，但是当时构建的实际系统非常小，仅限于手工编码的脚本，并且很难推广到更广泛的领域。

由于问题的复杂性，这方面的研究在20世纪80年代和90年代大多被忽视。在20世纪90年代末，人们对阅读理解的兴趣有了一些小小的复苏，例如Hirschman等人（1999）创建了一个阅读理解数据集，以及随后在ANLP/NAACL 2000年举办了一个关于阅读理解测试作为基于计算机的理解系统评估的研讨会。数据集包括60个用于开发的故事和60个用于测试的三至六年级的故事，附有一些简单的who，what，when，where，why这样的简单问题。它只需要系统返回包含正确答案的句子。这一阶段开发的系统主要是基于规则的词包方法。例如DEEP READ 系统（Hirschman et al. 1999）中进行词干分析、语义类识别和代词解析等浅层语言处理，或者像是QUARC系统（Riloff and THElen，2000）中手动生成基于词汇和语义对应的规则或者是以上两个的组合体（Charnizak et al.， 2000）。这些系统在检索正确句子时达到了30%-40%的准确率。


在2013年至2015年之间，（人们）在将阅读理解定义为一种supervised learning问题方面做出了显著的努力。研究员以（文章，问题，回答）三元组的形式收集人类标注好的训练例子，希望我们可以训练统计模型来学习将一段话和问题形成的对映射到他们相对应的答案上面去：f（passage， question）–>answer。

在此期间，两个值得注意的数据集是MCTEST （Richardson et al.， 2013）和PROCESSBANK （Berant et al.， 2014）。MCTEST收集660个虚构的故事，每个故事有4个多选题（每个问题有4个假设答案，其中一个是正确的）（Table 2.1 （b））。PROCESSBANK旨在回答描述生物过程的段落中的二选择问题，并要求理解过程中实体和事件之间的关系。数据集由585个问题组成，分布在200段中。

在最初的MCTEST paper中，Richardson等人（2013）在没有利用任何训练数据的情况下，提出了几个基于规则的基线（baseline）。一种是启发式滑动窗口方法，它测量问题、答案和滑动窗口中单词之间的加权单词重叠/距离信息；另一种方法是通过将每个问答对转换为一个语句来运行现成的文本蕴涵系统。这个数据集后来启发了一系列机器学习模型（Sachan et al.， 2015；Narasimhan和Barzilay， 2015；Wang et al.， 2015）。这些模型大多建立在一个简单的max-margin学习框架之上，该框架具有丰富的手工设计的语言特性，包括句法依赖、语义框架、指代消解、篇章关系和单词嵌入。MC500的性能从63%略微提高到70%左右。在PROCESSBANK数据集上，Berant等人（2014）提出了一种统计模型，该模型首先学会预测流程结构，然后将问题映射到可以针对该结构执行的正式查询。同样，模型结合了大量的手工特征，最终在二分类任务上获得了66.7%的准确率。

与早期基于规则的启发式方法相比，这些机器学习模型取得了一定的进步。然而，它们的改进仍然相当有限，其缺点总结如下：
1. 这些模型严重依赖于现有的语言工具，如依赖依存解析和语义角色标记（SRL）系统。然而，这些语言表示任务还远远没有解决，现成的工具通常是从单个领域（的文章）（例如，newswire文章）训练而来，在实际使用中存在泛化问题。因此，利用现有的语言注释作为特性有时会在这些基于特性的机器学习模型中增加噪音，而更高级别的注释（例如，篇章关系与词性标记），会让情况变得更糟糕。
2. 模拟人类水平的理解是一个难以捉摸的挑战，而且总是很难从当前的语言表征中构建有效的特征。例如，对于图1.1中的第三个问题：How many friends does Alyssa have in this story？，当证据散布在整个文章中，基本不可能构建出一个有效特征的。
3. 尽管我们可以从人类标记的阅读理解示例中训练模型，这确实激励人心，但这些数据集仍然太小，无法支持表达性统计模型。例如，用于训练依存解析器的English Penn Treebank数据集包含39，832个示例，而在MCTEST中，用于训练的示例仅为1480个——更不用说阅读理解了，作为一项综合性的语言理解任务，阅读理解更加复杂，并且需要不同的推理能力。


这个领域的转折点出现在2015年。DeepMind研究人员Hermann等人（2015）提出了一种新颖而廉价的方案，用于为学习阅读理解模型创建大规模监督训练数据。他们还提出了一个神经网络模型——一个基于attention机制的LSTM模型，命名为THE ATTENTIVE READER——并证明它在很大程度上优于符号NLP方法。在实验中，在CNN数据集中，THE ATTENTIVE READER获得63.8%的准确率，而符号NLP系统最多获得50.9%的准确率。数据创建的思想如下：CNN和《每日邮报》附有一些要点，总结了文章中所包含的信息。他们将一篇新闻文章作为passage，通过使用一个placeholder 来替换一个实体（entity）的方式将其中的一个要点转换为一个完形填空式的问题，而答案就是这个被替换的实体。为了确保这个系统需要真正的理解文章来完成这个任务，而不是使用世界知识（译者，知识库，即符号系统）或者语言模型来回答问题，他们运行了实体识别和指代消解系统，并且将所有在指代链中提到的每个实体替换为一个抽象的实体标记（例如：@entity6，可以在Table2.1（a）中看到例子）。最后，他们几乎没有任何成本地收集了近100万个数据示例。

更进一步，我们的工作（Chen et al.， 2016）研究了这个有史以来第一个大型的阅读理解数据集，并证明了一个简单、精心设计的神经网络模型（第3.2节）能够将CNN数据集的性能提升到72.4%，这是另一个8.6%的绝对提升。更重要的是，与传统的基于特征的分类器相比，神经网络模型能够更好地识别词汇匹配和其释义。然而，尽管这个半合成的数据集为训练有效的统计模型提供了一个理想的方法，但我们的结论是，由于数据的创建方法和指代误差，该数据集似乎是有噪声的，并且对于进一步的推动相关进展的帮助是有限的。

为了解决这些限制，Rajpurkar等人（2016）收集了一个名为STANFORD QUESTION ANSWER DATASET（SQUAD）的新数据集。数据集包含了536篇维基百科文章中的107，785对问答对，这些问题都是由群体工作者提出的，每个问题的答案对应相应的文章中的一段文本 （表2.1 （c））。SQUAD是第一个具有自然问题的大规模阅读理解数据集。由于其高质量和可靠的自动评估，该数据集引起了NLP社区的极大兴趣，并成为该领域的中心基准。这反过来启发了一系列新的阅读理解模型（Wang and Jiang， 2017； Seo et al.， 2017； Chen et al.， 2017； Wang et al.， 2017； Yu et al.， 2018） 并且研究的进展十分迅速，截至2018年10月，表现最好的单一的系统实现了91.8%的F1得分（Devlin et al .， 2018），而这个已经超过91.2%，我们预期的人类表现，而最初的作者在2016年构建的基于特征的分类器只获得了51.0%的F1值。

目前所有在SQUAD上面表现最好的系统都是建立在端到端神经网络或深度学习模型上的（end-to-end neural networks， or deep learning models）。这些模型往往会先从将文章和问题中的每一个单词表示为一个稠密向量开始（例如，300维）。经过几次建模或者交互层，最后进行预测。所有的参数可以使用梯度下降算法或者它的变种一起进行优化。这一类模型可以被称为神经阅读理解（neural reading comprehension），我们将会在第三章详细的阐述他。不同于基于特征的分类起，神经阅读理解模型有几个优点。
1. 他们不依赖于任何下游的语言学特征（比如，依存分析或者指代消解），并且所有的特征是在一个统一的端到端的的框架中独立学习来的。这避免了语言学标注的噪音，并且也在可用的特征空间中提供了更好的了灵活性。
2. 传统的符号NLP系统受困于一个严重的问题：特征通常非常稀疏，并且泛化性非常差。例如，为了回答一个问题：
How many individual libraries make up the main school library？
而文章中的相关内容如下
“… Harvard Library， which is the world’s largest academic and private library system， comprsing 79 individual libraries with over 18 million volumes”
所以一个系统必须基于标记好的特征来学习comprising与make up的一致性，例如下面的特征： $ pw_i = comprising ∧ qw_j = make ∧ qw_{j+1} = up. $ 这里并没有足够的数据来给这些特征赋予正确的权重。这在所有的非神经NLP模型中是一个共有的问题。利用低维，稠密的词向量共享相似词语之间在统计上的强度，可以有效的缓解稀疏性。
3. 这些模型从从构建大量手工特征的劳动中解脱出来。因此，神经模型在概念上更简单，（研究）重点可以转移到神经结构的设计（译者注：可以从构建手工特征中解放，转而研究神经网络结构）。由于现代深度学习框架如TENSORFLOW和PYTORCH的发展，已经取得了很大的进步，现在开发新的模型又快又容易。

毫无疑问，在SQUAD上面达到人类表现程度是不可思议，并且可以说是我们在过去几年在NLP社区中看到的最大成果之一。然而，解决SQUAD任务并不能等于解决机器阅读理解。我们需要承认SQUAD是有限的。因为问题必须用文章中的一段文本来回答，而且大多数SQUAD的例子相对非常简单，并且不需要复杂的推理。

这个领域还在进一步发展。围绕着创建大规模、更具挑战性的阅读理解数据集这一主题，近年来出现了大量的数据集：TRIVIAQA （Joshi et al.， 2017）， RACE （Lai et al.， 2017）， QANGAROO （Welbl et al.， 2018）， NARRATIVEQA （Kocˇisky et al.， 2018）， MULTIRC （Khashabi et al.， 2018）， SQuAD 2.0 （Rajpurkar et al.， 2018）， HOTPOTQA （Yang et al.， 2018）等。这些数据从各种来源收集（Wikipedia， newswire articles， fictional stories or other Web resources），并且以不同的方式构建。他们的目的是应对许多之前没有被解决的挑战：独立于段落的问题，需要多个句子甚至多个文档来回答的问题，基于长文档（比如一本书）的问题，或者不能从段落中回答的问题。在撰写本文时，这些数据集大多还没有得到解决，并且最先进的方法和人类的水平之间仍然存在很大的差距。阅读理解已成为当今自然语言处理中最活跃的领域之一，仍有许多待解决的问题。


### 任务定义

阅读理解的任务可以表述为一个监督学习问题：

给定一组训练实例${(p_i, q_i, a_i)}^n_{i=1}$ ，目标是学习一个预测器f，它以一段文本p和一个相应的问题q作为输入，给出答案a作为输出。

f：（p， q） →a （2.1）

令$p=(p_1,p_2, … , p_{l_p})$，$q = （q_1，q_2，…，q_{l_q}）$，其中$l_p$和$l_q$分别表示文本（passage）和问题（question）的长度。V为预定义词汇表，则对于i=1，。。。。，$l_p$，$p_i∈V$，且i=1，。。。。，$l_q$，$q_i∈V$。在这里，我们只把文本p看作一个由lp单词序列表示的短段落。将其扩展到多段形式（Clark and Gardner， 2018）非常简单，其中p是一组段落，或者将其分解为更小的语言单元，如句子。


根据答案类型的不同，答案a可以采取完全不同的形式。一般来说，我们可以把现有的阅读理解任务分为四类：

1. 完形填空类型（Cloze style）：问题包含一个placeholder（占位符）。例如：

​ RTottenham manager Juande Ramos has hinted he will allow _____ to leave if the Bulgaria striker makes it clear he is unhappy.
在这些任务中，系统必须基于文本来猜测哪些词或实体来完善句子（问题）。并且答案要么是选择从一组预定义的候选集中选择要么是从一个完整的词汇表中选择。比如说，，在WHO-DID-WHAT数据集中 （Onishi et al .， 2016），答案必须是文本中的一个人名，而其候选集的大小平均为3.5。
2. 多项选择类型（Multiple choice）：在这个类别下，正确答案从k个假设答案中选择（比如：k=4） A={a1， …， ak} where ak = （ak，1，ak，2，…ak，la，k），ak，I < V
正确的答案可以是一个单词，一个短语或者是一句话。给出的假设答案中有一个是正确的，所以a必须从{a1，…ak}中选择。
3. 范围预测类型（Span prediction）：这个类别也被称为抽取式问答（extractive question answering）并且答案必须是文本中的一个范围。因此，答案可以表示为（a_start， a_end），其中1<=a_start<=a_end<=lp。并且答案对英语pastart，…paend。
4. 自由形式回答类型（Free-form answer）：最后一种类型允许答案是任何形式的文本（即，任意长度的单词序列），形式上：a∈V。


每个类型的问题所属典型数据集的示例：
1. CNN/DAILY MAIL （Hermann et al.， 2015） （cloze style），
2. MCTEST （Richardson et al.， 2013） （multiple choice），
3. SQUAD （Rajpurkar et al.， 2016） （span prediction）
4. NARRA- TIVEQA （Kocˇisky et al.， 2018） （free-form answer）.


它们的评估指标。

对于多项选择题或完形填空题，评估准确性非常简单：系统给出正确答案的问题的百分比，因为答案是从一小组假设答案中选择的。

对于范围预测任务，我们需要将预测的答案与正确答案进行比较。通常，我们使用Rajpurkar等人（2016）提出的两种评估指标，即精确匹配和部分得分：
1. 精准匹配（Exact match，EM）如果预测的答案等于正确答案，则精确匹配（EM）将分配满分1.0分，否则将分配满分0.0分。
2. F1得分（F1 score）计算预测答案和正确答案之间的平均单词重叠。预测答案和正确答案被看作一堆token，所以token-level的F1得分计算如下：
​	F1 = 2×Precision×Recall/（Precision+Recall）

对于自由形式的回答阅读理解任务，目前还没有最理想的评价标准。一种常见的方法是使用在自然语言生成（NLG）任务中使用的标准评估指标，如机器翻译或摘要，包括BLEU （Papineni et al.， 2002）、Meteor （Banerjee和Lavie， 2005）和ROUGE （Lin， 2004）。



### 阅读理解和问答系统

阅读理解与问答有着密切的关系。我们可以把阅读理解看作是问答的一个实例，因为它很本质上是基于一篇短文的问答问题。然而，尽管阅读理解和一般的问答问题在问题的形成、方法和评价上有许多共同的特点，但我们认为它们最终目标强调了不同的东西：
1. 问答的最终目标是建立一个能够自动回答人类提出的问题计算机系统，系统可以依赖任何资源。这些资源可以是结构化的知识库、非结构化的文本集合（百科全书、词典、新闻专线文章和一般Web文档）、半结构化的表，甚至是其他模式。为了提高QA系统的性能，人们在（1）如何搜索和识别相关资源，（2）如何集成来自不同信息片段的答案，甚至（3）研究人类在现实世界中通常会问哪些类型的问题上进行了大量的工作。
2. 然而，阅读理解（reading comprehension）强调的是文本理解（text understanding）和一些被认为是衡量语言理解程度的尖锐问题。因此，要回答这个问题，需要对给定的段落有深刻的理解。由于这一关键的区别，这一领域的早期作品大多集中在虚构的故事（Lehnert， 1977）（后来扩展到Wikipedia或Web文档），所以所有回答理解问题的信息都来自文章本身，而不是任何世界知识。这些问题也是专门为测试文本理解的不同方面而设计的。这种区别类似于人们通常在搜索引擎上问的问题与在人类阅读理解测试中通常会提出的问题。

类似地，早期的工作（Mitchell et al.，2009）使用术语微观阅读（micro-reading）和宏观阅读（macro-reading）来区分这两种情况。微阅读侧重于阅读单个文本文档，旨在提取该文档的完整信息内容（类似于我们的阅读理解设定），而宏观阅读则采用大文本集合（如Web）作为输入，提取文本中表达的事实而形成一个很大的集合，而不需要提取每一个事实。尽管宏观阅读则需要考察语言理解的更深层次，但是宏观阅读可以通过分析文本中事实的简单措辞，有效地利用跨文档的信息冗余。



### 数据集和模型

近年来阅读理解的成功主要是由两个关键部分驱动的：大型阅读理解数据集和端到端神经阅读理解模型。

一方面，大规模阅读理解数据集的创建使得训练神经模型成为可能，同时也展示了它们相对于符号NLP系统的竞争力。这些数据集的可用性进一步吸引了我们研究社区的大量关注，并激发了一系列建模创新。受益于所有这些努力，已经取得了巨大的进展。

另一方面，了解现有模型的性能有助于进一步认识现有数据集的局限性。这促使我们寻求更好的方法来构建更具挑战性的数据集，以实现文本的机器压缩的最终目标。

![ml-06-01](/images/DL-images/paper-006-01.png)


### 阅读理解神经网络模型

对于完形填空式问题，任务表述为预测正确的实体a∈E，该实体a∈E可以根据阅读短文p来填补问题q的空白（表2.1中有一个例子），其中E表示候选实体集。传统的线性、基于特征的分类器通常需要为每个候选实体e∈$\epsilon$构造一个特征向量fp，q（e）∈Rd，并学习一个权向量w∈Rd，使得正确答案a的排名要高于所有其他候选实体：

$$w􏰇^Tf_{p,q}(a) > w􏰇^Tf_{p,q}(e), ∀e ∈ \epsilon \ {a},$$

在为每个实体e构造好所有特征向量后，我们就可以应用任何流行的机器学习算法（如logistic回归或SVM）。在Chen等人（2016）中，我们选择使用LAMBDAMART （Wu等人，2010），因为它是一个自然的排序问题，而近来应用boost的决策树森林非常成功。

剩下的关键问题是我们如何从文章p，问题q和每个实体e中构建有用的特征向量？表3.1列出了我们为CNN/DAILY MAIL任务提出的8组特性。如表所示，这些特征被很好地设计并描述了实体的信息（例如，频率、位置以及它是否是一个问题/短文词），以及它们如何与短文/短文对齐（例如，共现、距离、线性和句法匹配）。一些特性（#6和#8）还依赖于语言工具，比如依赖关系解析和词性标记（决定一个单词是否是动词）。一般来说，对于非神经模型，如何构造一组有用的特征始终是一个挑战。有用的特征必须是有意义的，并且能够很好地适应特定的任务，同时又不能过于稀疏而不能很好地从训练集中概括出来。我们在之前的2.1.2节中已经讨论过，这在大多数基于特征的模型中是一个常见的问题。此外，使用现成的语言工具使模型更加昂贵，它们的最终性能取决于这些（语言工具的）注释的准确性。

![ml-06-02](/images/DL-images/paper-006-02.png)

Rajpurkar等人（2016）和Joshi等人（2017）也尝试分别为SQUAD和TRIVIAQA数据集构建基于特征的模型。除了范围预测任务，这些模型在本质上与我们的相似，他们需要首先确定一组可能的答案。对于SQUAD， Rajpurkar et al.（2016）将Stanford CoreNLP（Manning et al.， 2014）生成的parses中的所有成分作为候选答案；而对于TRIVIAQA， Joshi et al.（2017）考虑所有出现在句子中的n-gram（1≤n≤5），其中至少包含一个与问题相同的单词。他们还试图从选民分析中添加更多的词汇化特性和标签。对MCTEST数据集的多项选择问题也进行了其他尝试，如（Wang et al.， 2015），并使用了丰富的特性集，包括语义框架、单词嵌入和指代消解。



Word embeddings

第一个关键思想是将单词表示为低维（例如，300）真实值向量。在前深度学习时代，常见的是，把单词用一个词汇表中的索引来代表，这是一个使用一个one-hot向量符号变体：每个单词都被表示为一个高维、稀疏向量，只有代表这个单词的地方是1，其他地方都是0：

$$V_{car}=[0, 0, … 0, 0, 1, 0, … 0]^T$$

$$V_{vehicle}=[0, 1, … 0, 0, 0, 0, … 0]^T$$

这些稀疏向量最大的问题是它们在单词之间没有任何语义相似性，即，对于任意一对不同的单词a， b， cos（v_a， v_b） = 0。低维单词嵌入有效地解决了这一问题，相似的单词可以在几何空间中编码为相似的向量：cos（v_car， v_vechicle） < cos（v_car， v_man）。【使用cos的值来反映两个向量的相似度】

Word embeddings第一个关键思想是将单词表示为低维（例如，300）真实值向量。在前深度学习时代，常见的是，把单词用一个词汇表中的索引来代表，这是一个使用一个one-hot向量符号变体：每个单词都被表示为一个高维、稀疏向量，只有代表这个单词的地方是1，其他地方都是0：

$$V_{car}=[0, 0, … 0, 0, 1, 0, … 0]^T$$

$$V_{vehicle}=[0, 1, … 0, 0, 0, 0, … 0]^T$$

这些稀疏向量最大的问题是它们在单词之间没有任何语义相似性，即，对于任意一对不同的单词a， b， cos（v_a， v_b） = 0。低维单词嵌入有效地解决了这一问题，相似的单词可以在几何空间中编码为相似的向量：cos（v_car， v_vechicle） < cos（v_car， v_man）。

 这些单词嵌入可以有效地从大型无标记文本语料库中学习，这是基于单词出现在相似的上下文中往往具有相似的含义这一假设（也称为分布假设）。的确，从文本中学习单词嵌入有悠久的历史，最近的scalable算法和发布的预先训练的单词嵌入集，如WORD2VEC （Mikolov et al.， 2013）、GLOVE （Pennington et al.， 2014）和FASTTEXT （Bojanowski et al.， 2017），最终使从文本中学习单词嵌入得到了普及。它们已成为现代NLP系统的中流砥柱。


 Recurrent neural networks

 第二个重要的思想是使用递归神经网络（RNNs）对自然语言处理中的时态或段落进行建模。递归神经网络是一类适合处理变长序列的神经网络。更具体地说，它们递归地对序列x1……xn应用一个参数化函数：

 $$h_t=f(h_{t-1},x_t; \theta)$$

 对于NLP应用程序，我们将句子或段落表示为单词序列，其中每个单词都转换为向量（通常通过预先训练的单词嵌入）：x = x1，x2，…，xn∈R^d和h_t∈R^h可以对x1：t的上下文信息进行建模。

 Vanilla的RNNs采用下列的形式：

 $$h_t=tanh(W^{hh}h_{t-1}+W^{hx}x_t+b)$$

 其中Whh∈Rh×h，Whx∈Rh×d， b∈Rh为待学习参数。为了简化优化，提出了许多RNNs的变体。其中，长短时记忆网络（LSTMs） （Hochreiter and Schmidhuber， 1997）和门控循环单元（GRUs） （Cho et al.， 2014）是常用的一种。可以说，LSTM仍然是当今NLP应用中最有竞争力的RNN变体，也是我们将描述的神经模型的默认选择。在数学上，LSTMs可以表示为：

![ml-06-03](/images/DL-images/paper-006-03.png)

 其中所有的W和b都是待学习参数。

最后，RNN中一个有用的东西是bidirectional RNN：想法很简单：对于一个句子或者一个段落来说：x=x1,….xn，一个前向RNN从左到右学习，另一个反过来学习。

![ml-06-04](/images/DL-images/paper-006-04.png)

最后，我们定义h_t是将公式中的两个h做拼接得到的结果。这些表示可以有效编码左边和右边的上下文，并且适用于多种NLP任务的通用可训练特征提取组件。


Attention mechanism

第三个重要的组件是attention机制。这个机制首次在sequence-to-sequence模型（Sutskever et al., 2014）中被提出为神经机器翻译提出（Bahdanau et al., 2015; Luong et al., 2015）并且之后被延伸应用到别的NLP任务中。

关键的想法是，如果我们想要预测一句话的情感（sentiment），或者从一种语言的一句话翻译到另外一种语言，我们通常使用recurrent neural networks来对一句话做编码（encode）：h1, h2, …hn并且使用最后一个time step的hn来预测最后的情感标签或者是目标语言的第一个word：

$$P(Y = y) = exp(W_yh_n) / \sum_{y’}exp(W_{y’}h_n)$$

这要求模型可以压缩一句话的所有信息到一个固定长度的向量中，这会导致在提升性能上的信息瓶颈。注意力机制(attention)就是设计来解决这个问题的：与其将所有的信息都压缩在最后一个隐藏向量中，我们监督每一个time step，并且自适应地选择这些向量的子集：

$$\alpha_i= exp(g(h_i, w; \Theta_g)) / \sum_{i’=1}^n exp(g(h_{i’}, w; \Theta_g))$$

$$c= \sum_{i=1}^n \alpha_ih_i$$

这里的w可以是在训练过程中针对任务学习出来的向量，或者当作机器翻译中现在的目标隐藏状态，g是一个可以以多种不同方式选择的参数，比如说点乘，bilinear product或者是MLP的一个隐藏层：

$$g_{dot}(h_i, w) = h_i^Tw$$

$$g_{bilinear}(h_i, w) = h_i^TWw$$

$$g_{MLP}(h_i, w) = v^Ttanh(W^hh_i + W^ww)$$

简单来说，注意力机制对每一个$h_i$ 计算一个相似度分数，之后使用一个softmax方程来为每一个time step返回一个离散概率分布。因此$\alpha$本质上捕获的句子的哪些部分确实是相关，而c聚合了所有time step的信息，可用于最终的预测。我们不会在这里讨论更多细节，感兴趣的读者可以参考Bahdanau等人(2015);Luong等(2015)。

注意力机制已经被证明在大量的应用是有广泛的影响力，并且成为神经NLP模型的一个组成部分。最近，Parikn等人（2016）和Vaswani等人（2017）推测注意力机制并不一定非要和RNN一起使用，并且可以单纯得基于word embeddings和前向神经网络建立，同时提供最小的序列信息。这类方法通常需要更少的参数，并且更加容易并行和规模变化。特别的，Vaswani等人在2017年的论文中提出的transformer已经变成了最近的趋势。

![ml-06-05](/images/DL-images/paper-006-05.png)



STANFORD ATTENTIVE READER 模型

我们的模型受到Hermann et al.（2015）中描述的ATTENTIVE READER以及其他同一时期工作的启发，并且满怀着让模型简单高效的目标。我们首先描述了模型解决范围预测问题的全形式（我们在Chen et al（2017）中预测了），之后我们讨论了其他的变种。













---
参考资料
1. [Welcome to chendq-thesis-ZH’s documentation!](https://chendq-thesis-zh.readthedocs.io/en/latest/index.html)
