---
title: 【NLP】【CS224N】attention
date: 2018-12-03 13:48:31
---


注意力机制即 Attention mechanism  


在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再解码，因此， c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。




### Attention
Attention模型的基本表述可以这样理解成：  

当我们人在看一样东西的时候，我们当前时刻关注的一定是我们当前正在看的这样东西的某一地方，换句话说，当我们目光移到别处时，注意力随着目光的移动也在转移。   

这意味着，当人们注意到某个目标或某个场景时，该目标内部以及该场景内每一处空间位置上的注意力分布是不一样的。   

这一点在如下情形下同样成立：当我们试图描述一件事情，我们当前时刻说到的单词和句子和正在描述的该事情的对应某个片段最先关，而其他部分随着描述的进行，相关性也在不断地改变。  

从上面两种情形来看，对于 Attention的作用角度出发，我们就可以从两个角度来分类 Attention种类：   

1. 空间注意力 Spatial Attention   
2. 时间注意力 Temporal Attention   

这样的分类更多的是从应用层面上，而从 Attention的作用方法上，可以将其分为 Soft Attention 和 Hard Attention，这既我们所说的， Attention输出的向量分布是一种one-hot的独热分布还是soft的软分布，这直接影响对于上下文信息的选择作用。  

### 为什么要加入Attention
1. 当输入序列非常长时，模型难以学到合理的向量表示
2. 序列输入时，随着序列的不断增长，原始根据时间步的方式的表现越来越差，这是由于原始的这种时间步模型设计的结构有缺陷，即所有的上下文输入信息都被限制到固定长度，整个模型的能力都同样收到限制，我们暂且把这种原始的模型称为简单的编解码器模型
3. 编解码器的结构无法解释，也就导致了其无法设计

### 长序列带来的问题
使用传统编码器-解码器的RNN模型先用一些LSTM单元来对输入序列进行学习，编码为固定长度的向量表示；然后再用一些LSTM单元来读取这种向量表示并解码为输出序列。   
采用这种结构的模型在许多比较难的序列预测问题（如文本翻译）上都取得了最好的结果，因此迅速成为了目前的主流方法。
这种结构在很多其他的领域上也取得了不错的结果。然而，它存在一个问题在于：输入序列不论长短都会被编码成一个固定长度的向量表示，而解码则受限于该固定长度的向量表示。  

这个问题限制了模型的性能，尤其是当输入序列比较长时，模型的性能会变得很差（在文本翻译任务上表现为待翻译的原始文本长度过长时翻译质量较差）。  

>“一个潜在的问题是，采用编码器-解码器结构的神经网络模型需要将输入序列中的必要信息表示为一个固定长度的向量，而当输入序列很长时则难以保留全部的必要信息（因为太多），尤其是当输入序列的长度比训练数据集中的更长时。”  
— Dzmitry Bahdanau, et al., [Neural machine translation by jointly learning to align and translate, 2015  ](https://arxiv.org/abs/1409.0473)  

### 使用Attention机制
Attention机制的基本思想是：打破了传统编码器-解码器结构在编解码时都依赖于内部一个固定长度向量的限制。  
Attention机制的实现是 通过保留LSTM编码器对输入序列的中间输出结果，然后训练一个模型来对这些输入进行选择性的学习并且在模型输出时将输出序列与之进行关联。  

换一个角度而言，输出序列中的每一项的生成概率取决于在输入序列中选择了哪些项。  

Attention-based Model 其实就是一个相似性的度量，当前的输入与目标状态约相似，那么在当前的输入的权重就会越大。就是在原有的model上加入了Attention的思想。  

>没有attention机制的encoder-decoder结构通常把encoder的最后一个状态作为decoder的输入（可能作为初始化，也可能作为每一时刻的输入），但是encoder的state毕竟是有限的，存储不了太多的信息，对于decoder过程，每一个步骤都和之前的输入都没有关系了，只与这个传入的state有关。attention机制的引入之后，decoder根据时刻的不同，让每一时刻的输入都有所不同。


### 序列编码
深度学习做NLP的方法，基本上都是先将句子分词，然后每个词转化为对应的词向量序列。这样一来，每个句子都对应的是一个矩阵$\boldsymbol{X}=(\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_t)$，其中$\boldsymbol{x}_i$都代表着第$i$个词的词向量（行向量），维度为$d$维，故$\boldsymbol{X}\in \mathbb{R}^{n\times d}$。这样的话，问题就变成了编码这些序列了。

第一个基本的思路是RNN层，RNN的方案很简单，递归式进行：
$$\boldsymbol{y}_t = f(\boldsymbol{y}_{t-1},\boldsymbol{x}_t)$$
不管是已经被广泛使用的LSTM、GRU还是最近的SRU，都并未脱离这个递归框架。RNN结构本身比较简单，也很适合序列建模，但RNN的明显缺点之一就是无法并行，因此速度较慢，这是递归的天然缺陷。另外我个人觉得RNN无法很好地学习到全局的结构信息，因为它本质是一个马尔科夫决策过程。
第二个思路是CNN层，其实CNN的方案也是很自然的，窗口式遍历，比如尺寸为3的卷积，就是
$$\boldsymbol{y}_t = f(\boldsymbol{x}_{t-1},\boldsymbol{x}_t,\boldsymbol{x}_{t+1})$$
在FaceBook的论文中，纯粹使用卷积也完成了Seq2Seq的学习，是卷积的一个精致且极致的使用案例，热衷卷积的读者必须得好好读读这篇文论。CNN方便并行，而且容易捕捉到一些全局的结构信息，笔者本身是比较偏爱CNN的，在目前的工作或竞赛模型中，我都已经尽量用CNN来代替已有的RNN模型了，并形成了自己的一套使用经验，这部分我们以后再谈。

Google的大作提供了第三个思路：纯Attention！单靠注意力就可以！RNN要逐步递归才能获得全局信息，因此一般要双向RNN才比较好；CNN事实上只能获取局部信息，是通过层叠来增大感受野；Attention的思路最为粗暴，它一步到位获取了全局信息！它的解决方案是：
$$\boldsymbol{y}_t = f(\boldsymbol{x}_{t},\boldsymbol{A},\boldsymbol{B})$$
其中$\boldsymbol{A},\boldsymbol{B}$是另外一个序列（矩阵）。如果都取$\boldsymbol{A}=\boldsymbol{B}=\boldsymbol{X}$，那么就称为Self Attention，它的意思是直接将$\boldsymbol{x}_t$与原来的每个词进行比较，最后算出$\boldsymbol{y}_t$！

### Attention层
#### Attention定义



---
### 参考资料
1. [深度学习中 的 Attention机制](https://blog.csdn.net/guohao_zhang/article/details/79540014)
2. [浅谈Attention-based Model【原理篇】](https://blog.csdn.net/wuzqchom/article/details/75792501)
3. [浅谈Attention-based Model【源码篇】](https://blog.csdn.net/wuzqChom/article/details/77918780)
4. [Attention in Long Short-Term Memory Recurrent Neural Networks ](https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/)
5. [Deep Learning基础–理解LSTM/RNN中的Attention机制 ](https://www.cnblogs.com/shixiangwan/p/7573589.html)
6. [Attention注意力机制--原理与应用](https://blog.csdn.net/joshuaxx316/article/details/70665388)  
7. [完全图解RNN、RNN变体、Seq2Seq、Attention机制](https://zhuanlan.zhihu.com/p/28054589)
