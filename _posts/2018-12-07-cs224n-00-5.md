---
title: 【NLP】【CS224N】transformer
date: 2018-12-07 11:48:31
---

Attention is a concept that helped improve the performance of neural machine translation applications. The Transformer – a model that uses attention to boost the speed with which these models can be trained.



---
参考资料：  
1. [Transformer](https://blog.csdn.net/YQMind/article/details/80864133)
2. [illustrated-transformer](https://jalammar.github.io/illustrated-transformer/)
3. [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
4. [《Attention is All You Need》浅读（简介+代码）](https://kexue.fm/archives/4765)
5. [对Attention is all you need 的理解](https://blog.csdn.net/mijiaoxiaosan/article/details/73251443)
6. [一文读懂「Attention is All You Need」| 附代码实现](https://yq.aliyun.com/articles/342508?utm_content=m_39938)
