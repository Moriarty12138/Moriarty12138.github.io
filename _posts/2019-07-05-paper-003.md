---
title: 【论文研读】 003 Mem2Seq
date: 2019-07-05 10:13:00
---

1804.08217

Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems

author:Andrea Madotto∗, Chien-Sheng Wu∗, Pascale Fung  
Human Language Technology Center  
Center for Artificial Intelligence Research (CAiRE)  
Department of Electronic and Computer Engineering  
The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong  
[eeandreamad,cwuak,pascale]@ust.hk  


### 论文动机/背景

将端到端的任务型对话系统与知识库相结合。


在之前的任务型对话系统中，查询外部知识库的能力是必不可少的。
response受到对话历史和查询结果的指引。

尽管通过结合领域特定知识和槽填充技术(slot-filling techniques)来确保这种流水线系统(pipelined system)的稳定性，
但是对模块之间的依赖性建模是复杂的并且知识库KB解释需要人力。


最近端到端的对话系统模型采用RNN的Seq2Seq模型取得了一些效果。
它们可以直接将纯文本对话历史映射到输出响应，
并且对话状态是潜在的，
因此不需要手工制作的状态标签。
引入了基于注意力的复制机制之后，
将字直接从输入源复制到输出响应。
使用这种机制，即使在对话历史中出现未知令牌，模型仍然能够生成正确且相关的实体。


连接知识库的对话系统仍然有两个主要问题
1. 由于RNN在长序列上的不稳定性，将KB信息整合到RNN隐藏状态很难
2. 处理长序列非常耗时尤其是加入注意力机制


### 论文贡献
这篇论文提出了一个新颖而且简单的端到端可辨别的模型Mem2Seq。

Mem2Seq is the first neural generative model that combines the multi-hop attention over memories with the idea of pointer network.  
Mem2Seq是第一个将记忆中的多跳注意力与指针网络理念相结合的神经生成模型。

模型结构并不复杂，但是取得了很好的效果而且速度很快。



### Mem2Seq如何解决这些问题



### 模型结构
