---
title: 【西瓜书】 007 贝叶斯分类器
date: 2019-06-10 20:24:00
---

### 贝叶斯决策论

贝叶斯决策论（Bayesian decision theory）是概率论框架下实施决策的基本方针。
对分类任务来说，在所有相关概率都已知的情况下，贝叶斯决策论考虑如何基于这些概率和误判才选择最优的类别标记。

假设有$N$种可能的类别标记，即$\mathcal{Y} = {c_1, c_2, ..., c_N}$，$\lambda_{ij}$是将一个真实标记为$c_j$的样本误分类为$c_i$所产生的损失。
基于后验概率$P(c_i|x)$可获得将样本$x$分类为$c_i$所产生的期望损失，即在样本$x$上的“条件风险”（conditional risk）。

$$R(c_i|x) = \sum_{j=1}^{N}{\lambda_{ij}P(c_j|x)}$$

寻找一个判定准则$h: \mathcal{X} -> \mathcal{Y}$，以最小化总体风险

$$R(h) = E_x[R(h(x)|x)]$$

对每个样本$x$，若$h$能最小化风险条件$R(h(x)|x)$，则总体风险$R(h)$也将被最小化。
这就产生了贝叶斯准则：
为最小化总体风险，只需在每个样本上选择那个使条件风险$R(c|x)$最小的类别标记。
即：

$$h^\ast(x) = \arg\min_{c \in \mathcal{Y}}{R(c|x)}$$

此时$h^\ast$称为贝叶斯最优分类器（Bayes optimal classifier），与之对应的总体风险$R(h^\ast)$称为贝叶斯风险（Bayes risk）。$1 - R(h^\ast)$反映了分类器所能够达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。

若目标最小化分类错误率，则错误率$\lambda_{ij}$可写为：

$$\lambda_{ij} = \left\{ \begin{array}{rcl} 0, & if i = j \\1, & otherwise,\end{array}\right$$

此时条件风险：

$$R(c|x) = 1 - P(c|x)$$

于是最小化分类错误率的贝叶斯最优分类器为：

$$h^\ast(x) = \arg\min_{c \in \mathcal{Y}}{P(c|x)}$$

即对于每个样本$x$，选择能使后验概率最大的类别标记。



欲使用贝叶斯判定准则来最小化决策风险，首先要获得后验概率。

机器学习所要的实现的是基于有限的训练样本尽可能的估计出后验概率$P(c|x)$。

大体来说，有两种策略：

1. 给定$x$，可通过直接建模$P(c|x)$来预测$c$，这样得到的是“判别式模型”
2. 先对联合概率分布$P(x, c)$建模，然后在由此获得$P(c|x)$，这样得到的模型是“生成式模型”





### 极大似然估计


### 朴素贝叶斯分类器


### 半朴素贝叶斯分类器


### 贝叶斯网


### EM算法
