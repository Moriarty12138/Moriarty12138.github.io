---
title: 【NLP基础任务】 2 词性标注
date: 2019-07-12 16:10:00
---


词性标注就是在给定句子中判定每个词的语法范畴，确定其词性并加以标注的过程，
这也是自然语言处理中一项非常重要的基础性工作，所有对于词性标注的研究已经有较长的时间，
在研究者长期的研究总结中，发现汉语词性标注中面临了许多棘手的问题。


中文词性标注的难点
1. 汉语是一种缺乏词形态变化的语言，词的类别不能像印欧语那样，直接从词的形态变化上来判别。
2. 常用词兼类现象严重。《现代汉语八百词》收取的常用词中，兼类词所占的比例高达22.5%，
而且发现越是常用的词，不同的用法越多。由于兼类使用程度高，兼类现象涉及汉语中大部分词类，
因而造成在汉语文本中词类歧义排除的任务量大。
3. 研究者主观原因造成的困难。语言学界在词性划分的目的、标准等问题上还存在分歧。
目前还没有一个统的被广泛认可汉语词类划分标准，词类划分的粒度和标记符号都不统一。
词类划分标准和标记符号集的差异，以及分词规范的含混性，给中文信息处理带来了极大的困难。


词性标注常见方法
1. 基于规则的词性标注方法
  * 基于规则的词性标注方法是人们提出较早的一种词性标注方法，
  其基本思想是按兼类词搭配关系和上下文语境建造词类消歧规则。
  早期的词类标注规则一般由人工构建。
  随着标注语料库规模的增大，可利用的资源也变得越来越多，
  这时候以人工提取规则的方法显然变得不现实，
  于是乎，人们提出了基于机器学习的规则自动提出方法。
2. 基于统计模型的词性标注方法
  * 统计方法将词性标注看作是一个序列标注问题。其基本思想是：
  给定带有各自标注的词的序列，我们可以确定下一个词最可能的词性。
  现在已经有隐马尔可夫模型（HMM）或条件随机域（CRF）等统计模型了，
  这些模型可以使用有标记数据的大型语料库进行训练，
  而有标记的数据则是指其中每一个词都分配了正确的词性标注的文本。
3. 基于统计方法与规则方法相结合的词性标注方法
  * 理性主义方法与经验主义相结合的处理策略一直是自然语言处理领域的专家们不断研究和探索的问题，
  对于词性标注问题当然也不例外。
  这类方法的主要特点在于对统计标注结果的筛选，只对那些被认为可疑的标注结果，
  才采用规则方法进行歧义消解，而不是对所有情况都既使用统计方法又使用规则方法。
4. 基于深度学习的词性标注方法
  * 可以当作序列标注的任务来做，目前深度学习解决序列标注任务常用方法包括
  LSTM+CRF、BiLSTM+CRF等。


词性标注任务数据集

人民日报1998词性标注数据集：https://pan.baidu.com/s/1fW908EQmyMv0XB5i0DhVyQ


词性标注工具推荐
1. Jieba：“结巴”中文分词：做最好的 Python 中文分词组件，可以进行词性标注。
2. SnowNLP：SnowNLP是一个python写的类库，可以方便的处理中文文本内容。
3. THULAC：THULAC（THU Lexical Analyzer for Chinese）
由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，
具有中文分词和词性标注功能。
4. StanfordCoreNLP：斯坦福的，具备各种nlp功能，包括词性标注。
5. Hanlp：HanLP是一系列模型与算法组成的NLP工具包，由大快搜索主导并完全开源，
目标是普及自然语言处理在生产环境中的应用。
6. NLTK：NLTK是一个高效的Python构建的平台,用来处理人类自然语言数据。
7. SpaCy：工业级的自然语言处理工具，遗憾的是不支持中文。

---

词性标注一般来讲比较简单，所以很少有单独工作来专门的词性标注任务。
一般都是词性标注和其他任务相结合。
首先我们来看一下联合的中文分词和词性标注任务。

第一种方法是基于字的序列标注方法，使用“BMES”和词性的交叉标签来给每个字打标签。
比如“B-NN”、“S-NR”等。相比于中文分词，分词和词性的联合任务需要更多的特征，
因此我们可以用更复杂的网络来进行抽取特征。

第二种方法是基于转移的方法，首先利用一个 BiLSTM 编码器来提取上下文特征，
在解码时每一步都预测一个动作。
动作的候选集合为是否分词以及词性。



---
参考资料
1. [自然语言处理基础技术之词性标注](https://zhuanlan.zhihu.com/p/50817277)
2. [NLP任务最新研究进展](https://github.com/sebastianruder/NLP-progress)
