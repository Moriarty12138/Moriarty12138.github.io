---
title: 【NLP】【CS224N】2.1 word2vec
date: 2018-11-03 19:42:31
---
来自S的视频。  

1. 拼写检查、关键字检索......
2. 文本挖掘
3. 文本分类
4. 机器翻译
5. 客服系统
6. 复杂对话系统

### 语言模型
p(s)=p(w1,w2,w3,w4,...,wn)  
=p(w1)p(w2|w1)p(w3|w1,w2)...p(wn|w1,w2,...,wn-1)  
p(S)被称为语言模型，即用来计算一个句子概率的模型。  
1.数据过于稀疏  
2.参数空间太大  


### N-gram模型
假设下一个词的出现依赖它前面的一个词：  
p(s)=p(w1,w2,w3,w4,...,wn)  
=p(w1)p(w2|w1)p(w3|w2)...p(wn|wn-1)  

假设下一个词的出现依赖它前面的两个词：  
p(s)=p(w1,w2,w3,w4,...,wn)  
=p(w1)p(w2|w1)p(w3|w1,w2)...p(wn|wn-2,wn-1)  

在实际问题中，并不指定跟前面所有的词都相关，而是只与前n个词相关。  
即N-gram模型  
解决了参数空间过大的问题。  

假设词典的大小是N，则模型参数的量级是(O(N^n))


### 词向量
word2vec  
