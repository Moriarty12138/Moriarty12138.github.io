---
title: 【NLP】【CS224N】transformer
date: 2018-12-07 11:48:31
---

### The Problem of Long-Term Dependencies

One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame.  

One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame.

In theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form.

Sadly, in practice, RNNs don't seem to be able to learn them.

Thankfully, LSTMs don’t have this problem!

###
